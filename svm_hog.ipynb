{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d7fd9f6-1271-4e4c-9c58-80a9a0a7dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn import MTCNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7525182a-9d40-428b-a318-8a8abaedaa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog(img_gray, cell_size=8, block_size=2, bins=9):\n",
    "    img = img_gray\n",
    "    h, w = img.shape # 128, 64\n",
    "    \n",
    "    # gradient\n",
    "    xkernel = np.array([[-1, 0, 1]])\n",
    "    ykernel = np.array([[-1], [0], [1]])\n",
    "    dx = cv2.filter2D(img, cv2.CV_32F, xkernel)\n",
    "    dy = cv2.filter2D(img, cv2.CV_32F, ykernel)\n",
    "    \n",
    "    # histogram\n",
    "    magnitude = np.sqrt(np.square(dx) + np.square(dy))\n",
    "    orientation = np.arctan(np.divide(dy, dx+0.00001)) # radian\n",
    "    orientation = np.degrees(orientation) # -90 -> 90\n",
    "    orientation += 90 # 0 -> 180\n",
    "    \n",
    "    num_cell_x = w // cell_size # 8\n",
    "    num_cell_y = h // cell_size # 16\n",
    "    hist_tensor = np.zeros([num_cell_y, num_cell_x, bins]) # 16 x 8 x 9\n",
    "    for cx in range(num_cell_x):\n",
    "        for cy in range(num_cell_y):\n",
    "            ori = orientation[cy*cell_size:cy*cell_size+cell_size, cx*cell_size:cx*cell_size+cell_size]\n",
    "            mag = magnitude[cy*cell_size:cy*cell_size+cell_size, cx*cell_size:cx*cell_size+cell_size]\n",
    "            # https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html\n",
    "            hist, _ = np.histogram(ori, bins=bins, range=(0, 180), weights=mag) # 1-D vector, 9 elements\n",
    "            hist_tensor[cy, cx, :] = hist\n",
    "        pass\n",
    "    pass\n",
    "    \n",
    "    # normalization\n",
    "    redundant_cell = block_size-1\n",
    "    feature_tensor = np.zeros([num_cell_y-redundant_cell, num_cell_x-redundant_cell, block_size*block_size*bins])\n",
    "    for bx in range(num_cell_x-redundant_cell): # 7\n",
    "        for by in range(num_cell_y-redundant_cell): # 15\n",
    "            by_from = by\n",
    "            by_to = by+block_size\n",
    "            bx_from = bx\n",
    "            bx_to = bx+block_size\n",
    "            v = hist_tensor[by_from:by_to, bx_from:bx_to, :].flatten() # to 1-D array (vector)\n",
    "            feature_tensor[by, bx, :] = v / LA.norm(v, 2)\n",
    "            # avoid NaN:\n",
    "            if np.isnan(feature_tensor[by, bx, :]).any(): # avoid NaN (zero division)\n",
    "                feature_tensor[by, bx, :] = v\n",
    "    \n",
    "    return feature_tensor.flatten() # 3780 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52bc0468-3b9a-4320-a9f5-e8b3cfb9511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(64, 128)):\n",
    "    try:\n",
    "        # Load image using OpenCV for better performance\n",
    "        image = cv2.imread(filename)\n",
    "        if image is None:\n",
    "            print(f\"Failed to load image: {filename}\")\n",
    "            return None\n",
    "\n",
    "        # Convert to RGB format (OpenCV loads in BGR by default)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Create the MTCNN detector\n",
    "        detector = MTCNN()\n",
    "\n",
    "        # Detect faces in the image\n",
    "        results = detector.detect_faces(image)\n",
    "        if len(results) == 0:\n",
    "            print(f\"No face detected in {filename}\")\n",
    "            return None\n",
    "\n",
    "        # Select the face with the highest confidence score\n",
    "        best_result = max(results, key=lambda res: res['confidence'])\n",
    "\n",
    "        # Extract the bounding box\n",
    "        x1, y1, width, height = best_result['box']\n",
    "        x1, y1 = max(0, x1), max(0, y1)  # Ensure coordinates are within bounds\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "\n",
    "        # Resize face to the model's required size\n",
    "        face = image[y1:y2, x1:x2]\n",
    "\n",
    "        # Convert the face region to grayscale for HOG\n",
    "        face_gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Resize the face to the required size for HOG\n",
    "        face_resized = cv2.resize(face_gray, required_size)\n",
    "\n",
    "        # Compute the HOG features for the face\n",
    "        hog_features = hog(face_resized)\n",
    "\n",
    "        return hog_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d31433f-d454-4fd4-97f3-63724d112450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and extract features\n",
    "def load_dataset(dataset_path):\n",
    "    X, y = [], []\n",
    "\n",
    "    for person_name in os.listdir(dataset_path):\n",
    "        person_folder = os.path.join(dataset_path, person_name)\n",
    "        if not os.path.isdir(person_folder):\n",
    "            continue\n",
    "\n",
    "        for img_name in os.listdir(person_folder):\n",
    "            img_path = os.path.join(person_folder, img_name)\n",
    "            \n",
    "            hog_features = extract_face(img_path)\n",
    "            if hog_features is not None:\n",
    "                X.append(hog_features)\n",
    "                y.append(person_name)\n",
    "        print('Finish loading examples for class: %s' % person_name)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385aa79f-ef8b-491e-b92b-bb28e7d9e06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading examples for class: Andy Samberg\n",
      "Finish loading examples for class: Billie Eilish\n",
      "Finish loading examples for class: Brad Pitt\n",
      "Finish loading examples for class: Camila Cabello\n",
      "Finish loading examples for class: Charlize Theron\n",
      "Finish loading examples for class: Claire Holt\n",
      "Finish loading examples for class: Elizabeth Olsen\n",
      "No face detected in dataset/Emma Stone\\Emma Stone73_1817.jpg\n",
      "No face detected in dataset/Emma Stone\\Emma Stone86_1830.jpg\n",
      "Finish loading examples for class: Emma Stone\n",
      "Finish loading examples for class: Henry Cavill\n",
      "Finish loading examples for class: Hugh Jackman\n",
      "Finish loading examples for class: Jennifer Lawrence\n",
      "Finish loading examples for class: Jessica Alba\n",
      "Finish loading examples for class: Margot Robbie\n",
      "Finish loading examples for class: Natalie Portman\n",
      "Finish loading examples for class: Neil Patrick Harris\n",
      "Finish loading examples for class: Robert Downey Jr\n",
      "Finish loading examples for class: Roger Federer\n",
      "Finish loading examples for class: Tom Cruise\n",
      "Finish loading examples for class: Winter\n",
      "Finish loading examples for class: Zac Efron\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_path = \"dataset/\"\n",
    "X, y = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a69ea9-4c76-43e3-b872-d627ea7731fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved\n"
     ]
    }
   ],
   "source": [
    "with open(\"data.pkl\", \"wb\") as file:\n",
    "    pickle.dump((X, y), file)\n",
    "\n",
    "print(\"Data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fdf2f9b-6284-44d2-b360-504204b71348",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pkl\", \"rb\") as file:\n",
    "    X, y = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcc47331-4dbf-4d29-80b8-a744b51735bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1573, 3780)\n",
      "X_test:  (394, 3780)\n",
      "y_train:  (1573,)\n",
      "y_test:  (394,)\n"
     ]
    }
   ],
   "source": [
    "# Train KNN\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"X_train: \",X_train.shape)\n",
    "print(\"X_test: \",X_test.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5200668a-09cc-44d5-94a3-ac969be53839",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3, weights = \"distance\", algorithm = \"ball_tree\", leaf_size=10, metric=\"euclidean\")\n",
    "\n",
    "pca = PCA(n_components=150, svd_solver=\"randomized\", whiten=True)\n",
    "svm = SVC(C=500, gamma=0.005, class_weight='balanced', kernel='rbf', random_state=42)\n",
    "model = make_pipeline(pca, svm)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fbeca874-e99b-43d0-9fe9-a0306c885062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of SVM is : 1.0\n",
      "Test accuracy of SVM is : 0.7284263959390863\n",
      "[[13  0  0  0  0  1  0  0  0  1  0  1  0  1  0  1  0  0  0  1]\n",
      " [ 0  6  0  0  0  2  0  1  0  0  0  1  1  1  2  0  0  0  0  0]\n",
      " [ 0  0 25  0  1  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0]\n",
      " [ 0  0  1 17  2  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 11  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  1  0  1 14  0  0  1  0  2  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  1 13  0  0  0  0  5  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  1 14  1  0  3  1  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0 10  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  2 18  0  0  0  0  0  0  0  1  0  1]\n",
      " [ 0  2  0  1  1  2  0  1  0  0 24  0  0  2  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  1  1  0  1  0  0  3 13  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 11  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  1  0  0  1  0  0  0  1 19  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  1  2  0  0  1  0  0 16  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  1  0  2 11  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0 10  0  0]\n",
      " [ 0  2  0  3  0  0  0  0  0  0  2  2  0  0  0  0  0  0  4  0]\n",
      " [ 0  0  1  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0 15]]\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       Andy Samberg       1.00      0.68      0.81        19\n",
      "      Billie Eilish       0.46      0.43      0.44        14\n",
      "          Brad Pitt       0.76      0.89      0.82        28\n",
      "     Camila Cabello       0.77      0.77      0.77        22\n",
      "    Charlize Theron       0.55      0.85      0.67        13\n",
      "        Claire Holt       0.58      0.58      0.58        24\n",
      "    Elizabeth Olsen       0.87      0.65      0.74        20\n",
      "         Emma Stone       0.78      0.64      0.70        22\n",
      "       Henry Cavill       0.56      0.83      0.67        12\n",
      "       Hugh Jackman       0.78      0.78      0.78        23\n",
      "  Jennifer Lawrence       0.71      0.71      0.71        34\n",
      "       Jessica Alba       0.52      0.65      0.58        20\n",
      "      Margot Robbie       0.65      0.85      0.73        13\n",
      "    Natalie Portman       0.68      0.79      0.73        24\n",
      "Neil Patrick Harris       0.89      0.67      0.76        24\n",
      "   Robert Downey Jr       0.79      1.00      0.88        23\n",
      "      Roger Federer       1.00      0.69      0.81        16\n",
      "         Tom Cruise       0.91      0.83      0.87        12\n",
      "             Winter       1.00      0.31      0.47        13\n",
      "          Zac Efron       0.83      0.83      0.83        18\n",
      "\n",
      "           accuracy                           0.73       394\n",
      "          macro avg       0.75      0.72      0.72       394\n",
      "       weighted avg       0.76      0.73      0.73       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "svm_test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Training accuracy of SVM is : {svm_train_acc}\")\n",
    "print(f\"Test accuracy of SVM is : {svm_test_acc}\")\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17c201-2e81-47f6-8dbb-d605f5e73eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
